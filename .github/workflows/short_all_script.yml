name: Run short all script

on:
  workflow_dispatch:
    inputs:
      hf_key:
        description: 'Hugging Face token (runtime input). This will be passed to the job as HF_TOKEN.'
        required: true
        type: string

jobs:
  run-script:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    env:
      # HF token is set dynamically from the workflow dispatch input (hf_key)
      HF_TOKEN: ${{ github.event.inputs.hf_key }}

      # MODEL_DEST_PATH and REPO_ID are set here (not dynamic). Change paths if you like.
      MODEL_DEST_PATH: ${{ github.workspace }}/models/Llama-2-7B-chat.gguf
      REPO_ID: TheBloke/Llama-2-7B-Chat-GGUF
      USE_AUTH: "true"
      SELECT_STRATEGY: "llama-2-7b-chat.Q5_K_M.gguf"
      VERBOSE: "true"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Show disk
        run: |
          df -h

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt --no-cache-dir
          pip cache purge

      - name: Show disk
        run: |
          df -h

      - name: Show environment (debug)
        run: |
          echo "HF_TOKEN set? -> ${HF_TOKEN:+YES}"
          echo "MODEL_DEST_PATH -> $MODEL_DEST_PATH"
          echo "REPO_ID -> $REPO_ID"
          echo "SELECT_STRATEGY -> $SELECT_STRATEGY"
          python -c "import psutil,sys; print('Total RAM GB:', psutil.virtual_memory().total/1024**3 if 'psutil' in sys.modules else 'psutil missing')"

      - name: Run download & test script
        run: |
          cd Script_Drive1
          python3 test_local_llm.py
          pip cache purge
        env:
          HF_TOKEN: ${{ github.event.inputs.hf_key }}
          MODEL_DEST_PATH: ${{ github.workspace }}/models/Llama-2-7B-chat.gguf
          REPO_ID: TheBloke/Llama-2-7B-Chat-GGUF

      - name: Show disk
        run: |
          df -h

      - name: Run your script (llm)
        env:
          R_HOURS: "6"
        run: |
          cd Script_Drive1
          python local_llm.py

      - name: Show disk
        run: |
          df -h

      - name: Upload debug artifacts (if present)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: llm-debug-artifacts
          path: |
            Script_Drive1/generated_complete_script/**
            Script_Drive1/image_response/**
            Script_Drive1/youtube_response/**
            Script_Drive1/narration_response/**

      - name: Cleanup workspace and temp files (Linux/macOS)
        if: always()
        run: |
          echo "Cleaning workspace..."
          # remove everything under the workspace (but not the workspace dir itself)
          rm -rf "$GITHUB_WORKSPACE"/* || true
          rm -rf /tmp/* || true
          # optional: remove runner temp & actions directories (self-hosted)
          rm -rf /home/runner/work/_temp/* || true
          rm -rf /home/runner/work/_tool/* || true
          # optional docker cleanup (if you use docker)
          docker system prune -af --volumes || true
